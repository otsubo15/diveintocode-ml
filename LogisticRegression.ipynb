{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "class ScratchLogisticRegression:#呼び出しでは引数に(n_iteration=100,alfa = 0.05)が入っているが元にはかかなくていいのか\n",
    "    \"\"\"\n",
    "    ロジスティック回帰のスクラッチ実装\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iteration : int\n",
    "      イテレーション数\n",
    "    alfa : float 学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "      \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.theta : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.theta_list\n",
    "    self.loss : 次の形のndarray, shape (self.n_iteration)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.n_iteration)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_iteration, alfa,lam):\n",
    "        self.n_iteration = n_iteration # イテレーター最急降下を繰り返す回数\n",
    "        self.alfa = alfa  #学習率\n",
    "        self.lam = lam \n",
    "        #self.bias = bias# バイアス項を入れるかどうか、メソッド呼び出しで定義する\n",
    "        #self.verbose = verbose# 学習過程を出力するかどうか、メソッド呼び出しで定義する\n",
    "        self.theta = np.array(None) #線形回帰のパラメータベクトル\n",
    "        self.y_hat = np.array(None) #線形回帰のパラメータベクトル\n",
    "        self.y_val_hat = np.array([]) #線形回帰のパラメータベクトル\n",
    "        self.theta_list = np.array(None)\n",
    "        self.y_hat_linear = 0\n",
    "        # 目的関数の値を記録する配列を用意\n",
    "        self.loss = np.array([])#訓練データに対する損失の記録 次の形のndarray, shape (self.n_iteration)\n",
    "        self.val_loss = np.array([])#検証データに対する損失の記録 次の形のndarray, shape (self.n_iteration)\n",
    "      \n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \n",
    "        #------Xにバイアス項を追加する------\n",
    "\n",
    "        #データ数の１の配列\n",
    "        bias1 = np.repeat(1,len(X))\n",
    "\n",
    "        #目的変数のデータフレームにバイアス項を追加\n",
    "        X = np.insert(X, 0, bias1, axis=1)\n",
    "\n",
    "        #print(\"X.size:{}\".format(X.size)) #------検証中--------\n",
    "        #print(\"type(X):{}\".format(type(X))) #------検証中--------\n",
    "        #print(\"X.shape:{}\".format(X.shape)) #------検証中--------\n",
    "        #print(\"X:{}\".format(X)) #------検証中--------\n",
    "\n",
    "        #------X_valにバイアス項を追加する------\n",
    "\n",
    "        #データ数の１の配列\n",
    "        bias1 = np.repeat(1,len(X_val))\n",
    "\n",
    "        #目的変数のデータフレームにバイアス項を追加\n",
    "        X_val = np.insert(X_val, 0, bias1, axis=1)\n",
    "\n",
    "        #         print(\"X_val.size:{}\".format(X_val.size)) #------検証中--------\n",
    "        #         print(\"type(X_val):{}\".format(type(X_val))) #------検証中--------\n",
    "        #         print(\"X_val.shape:{}\".format(X_val.shape)) #------検証中--------\n",
    "        #         print(\"X_val:{}\".format(X_val)) #------検証中--------\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.θをXのデータ数と同じゼロが入ったndarrayとする（109行目付近でlen(self.theta)を使う為）\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        #print(X)\n",
    "        \n",
    "        for i in range(self.n_iteration):\n",
    "            #print(\"イテレーション回数i:{}\".format(i)) #------デバック--------\n",
    "            \n",
    "            # ①仮定関数呼び出し\n",
    "            self.y_hat = self._Logistic_hypothesis(X)\n",
    "\n",
    "            # ②パラメータthetaの算出　最急降下法によるパラメータthetaの更新値計算\n",
    "            self.theta = self._gradient_descent(X,y,self.y_hat)\n",
    "            #print(self.theta)\n",
    "            #print(\"②self.theta:{}\".format(self.theta)) #------検証中--------\n",
    "            \n",
    "            # ③　②の新パラメータthetaを使いXのself.y_hatを計算\n",
    "            self.y_hat = self._Logistic_hypothesis(X)\n",
    "#             self.y_hat = self.predict(X)\n",
    "#             print(\"i:{}\".format(i)) #------検証中--------\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"③新theta代入後のself.y_hat{}\".format(self.y_hat)) #------検証中--------\n",
    "            \n",
    "            #-------------------------\n",
    "\n",
    "            # ④ XとX_valの目的関数値を出力し、ndarrayに格納\n",
    "                        \n",
    "            #　Xの目的関数の値をself.loss_funcを出力\n",
    "            self.loss_func = self.Loss_function(X,self.y_hat, y)\n",
    "            #print(\"④Xの損失関数self.loss_func:{}\".format(self.loss_func)) #------検証中--------\n",
    "            \n",
    "            #Xの損失関数をndarrayに格納\n",
    "            self.loss = np.append(self.loss , self.loss_func)\n",
    "            \n",
    "            #-------------------------\n",
    "            \n",
    "            #X_valの目的関数の値をself.y_val_hatとして出力\n",
    "            self.y_val_hat = self._Logistic_hypothesis(X_val)\n",
    "#             self.y_val_hat = self.predict(X_val) #self._linear_hypothesis()の値を受け取る\n",
    "            \n",
    "            #次に上で出したself.y_val_hatを使ってX_testの損失関数を出力する\n",
    "            self.val_loss_func = self.Loss_function(X_val,self.y_val_hat, y_val)\n",
    "            #print(\"④X_valの損失関数self.loss_func:{}\".format(self.val_loss_func)) #------検証中--------\n",
    "            \n",
    "            #X_valの損失関数を専用のndarrayであるself.val_lossに格納\n",
    "            self.val_loss = np.append(self.val_loss,self.val_loss_func)\n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    # ①仮定関数作成\n",
    "    def _Logistic_hypothesis(self,X):\n",
    "    \n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データ\n",
    "          \n",
    "        self.theta: パラメータベクトル\n",
    "        \n",
    "        X_j : j番目の特徴量\n",
    "        theta_j: j番目のパラメータ（重み）\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.y_hat：目的変数の予測値（次の形のndarray, shape (n_samples, 1)ロジスティック回帰の仮定関数から算出）\n",
    "        \n",
    "        \"\"\"\n",
    "                \n",
    "        #1次元配列は転置できないのでreshapeで２次元に変えてから転置する\n",
    "        theta_2dim = self.theta.reshape(( 1, len(self.theta)))\n",
    "        #print(theta_2dim.transpose())\n",
    "        \n",
    "        \n",
    "        \n",
    "        #n個の特徴量の仮定関数hθにおける特徴量をXjとし一般式としたもの\n",
    "#         print(\"X.shape①仮定関数作成:{}\".format(X.shape)) #------検証中--------\n",
    "#         print(\"theta_2dim.shape①仮定関数作成:{}\".format(theta_2dim.shape)) #------検証中--------\n",
    "\n",
    "        \n",
    "        self.y_hat_linear = X @ theta_2dim.transpose()  #ロジスティック回帰の仮定関数\n",
    "                        \n",
    "        #----ロジスティック回帰の仮定関数----\n",
    "        self.y_hat = 1 / (1 + (math.e)** -(self.y_hat_linear))#ダイバー記載の公式 math.e=2.718281828459045\n",
    "        \n",
    "        #print(\"①のself.y_hat:{}\".format(self.y_hat)) #------検証中--------\n",
    "        return self.y_hat\n",
    "        \n",
    "                     \n",
    "    #②self.thetaの最急降下を１回行う          \n",
    "    def _gradient_descent(self,X,y,y_hat):\n",
    "        \"\"\"\n",
    "        最急降下を１回行ったself.thetaを計算する\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)訓練データ\n",
    "        self.theta: パラメータベクトル\n",
    "        self.y_hat\n",
    "        self.alfa: 学習率\n",
    "        self.lam: 正則化パラメータ\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.theta：最急降下を１回行ったパラメータ\n",
    "        \n",
    "        \"\"\"\n",
    "                \n",
    "        #データの数（行の数）\n",
    "        m = len(X[:,0])\n",
    "        #print(\"m:{}\".format(self.m)) #------検証中--------\n",
    "        \n",
    "        #特徴量の数（列の数）\n",
    "        n = len(X[0,:])\n",
    "        #print(\"n:{}\".format(n)) #------検証中--------\n",
    "        #----パラメータself.thetaを再急降下法で最適化する一般式----\n",
    "\n",
    "        #error(予測値と真の値の差分）のデータ数iの値を１～ｍまで（データ数ある分だけ）合計し、θの一般式self.θ[j] を出して、それを特徴量の数ｎ個分をfor文で作り出す\n",
    "        for j in range(n): # n:特徴量の数（列の数） \n",
    "            \n",
    "            #error(予測値と真の値の差分）にX[i,j]を掛けた値をｍ（データ数の数）個分足すので、足した変数をsum_errorとする\n",
    "            sum_error = 0 #とりあえず定義（初期値）for文の為。値はゼロ\n",
    "            \n",
    "            #ここはerrorをｍ個作ってそれをsum_errorに足していく\n",
    "            \n",
    "\n",
    "            #             print(type(self.y_hat))\n",
    "            #             print(type(y))\n",
    "            \n",
    "            \n",
    "            \n",
    "            for i in range( m ): \n",
    "                \n",
    "                #error(予測値と真の値の差分）\n",
    "                error =self.y_hat[i] - y[i]\n",
    "                \n",
    "                #sum_errorはデータ数（ｍ）分　error * X[i,j]を繰り返し足し続けた合計値\n",
    "                sum_error += error * X[i,j] #Σi=0~m　((hθ_Xj) - yi)を全部足した\n",
    "                \n",
    "            #最急降下法により次のthetaを求める一般式。ここでθを0からｎ個作っていく\n",
    "            self.theta[j] = self.theta[j] - self.alfa * ((1 / m)  * sum_error + ((self.lam / m ) * self.theta[j]) )\n",
    "            self.theta_list = np.append(self.theta_list ,self.theta[j])\n",
    "#             print(\"self.theta_list:{}\".format(self.theta_list)) #------検証中--------\n",
    "\n",
    "            \n",
    "        return self.theta\n",
    "    \n",
    "    # ③ロジスティック回帰を使いテストデータの目的変数を推定する\n",
    "    def predict(self, X):\n",
    "            \n",
    "        \"\"\"\n",
    "        thetaとXをロジスティック回帰仮定関数に代入し、Xに対しｙの推定値を出力\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self.y_hat : 次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        #データ数の１の配列\n",
    "        bias1 = np.repeat(1,len(X))\n",
    "\n",
    "        #目的変数のデータフレームにバイアス項を追加\n",
    "        X = np.insert(X, 0, bias1, axis=1)\n",
    "        print(\"X[:,0]:{}\".format(X[:,0])) #------検証中--------\n",
    "        print(\"X[:,1]:{}\".format(X[:,1])) #------検証中--------\n",
    "\n",
    "#         if X[:,0] == X[:,1]:\n",
    "#             np.delete(X, 0, 1)\n",
    "#         else:\n",
    "#             pass\n",
    "        \n",
    "                \n",
    "        #1次元配列は転置できないのでreshapeで２次元に変えてから転置する\n",
    "        theta_2dim = self.theta.reshape(( 1, len(self.theta)))\n",
    "#         print(\"self.theta:{}\".format(self.theta)) #------検証中--------\n",
    "                \n",
    "        #n個の特徴量の仮定関数hθにおける特徴量をXjとし一般式としたもの\n",
    "#         print(\"X.shape:{}\".format(X.shape)) #------検証中--------\n",
    "#         print(\"theta_2dim.shape:{}\".format(theta_2dim.shape)) #------検証中--------\n",
    "#         print(\"theta_2dim:{}\".format(theta_2dim)) #------検証中--------\n",
    "        #ロジスティック回帰の仮定関数の行列積部分\n",
    "#         print(\"X.size:{}\".format(X.size)) #------検証中--------\n",
    "#         print(\"type(X):{}\".format(type(X))) #------検証中--------\n",
    "#         print(\"X.shape:{}\".format(X.shape)) #------検証中--------\n",
    "        #print(\"X:{}\".format(X)) #------検証中--------\n",
    "#         print(\"theta_2dim.transpose() .size:{}\".format(theta_2dim.transpose() .size)) #------検証中--------\n",
    "#         print(\"type(theta_2dim.transpose() ):{}\".format(type(theta_2dim.transpose() ))) #------検証中--------\n",
    "#         print(\"theta_2dim.transpose() .shape:{}\".format(theta_2dim.transpose() .shape)) #------検証中--------\n",
    "#         print(\"theta_2dim.transpose() :{}\".format(theta_2dim.transpose() )) #------検証中--------\n",
    "#         print(\"------検証中---------\") \n",
    "        \n",
    "        print(\"X.shape③目的変数:{}\".format(X.shape)) #------検証中--------\n",
    "        print(\"theta_2dim.shape③目的変数:{}\".format(theta_2dim.shape)) #------検証中--------\n",
    "        print(\"X:{}\".format(X)) #------検証中--------\n",
    "\n",
    "    \n",
    "        self.y_hat_linear = X @ theta_2dim.transpose()  \n",
    "        \n",
    "                        \n",
    "        #----ロジスティック回帰の仮定関数----\n",
    "        self.y_hat = 1 / (1 + (math.e)** -(self.y_hat_linear))#ダイバー記載の公式 math.e=2.718281828459045\n",
    "        \n",
    "        \n",
    "        return self.y_hat\n",
    "    \n",
    "#     #self.y_hatを1と0のラベルとしたもの\n",
    "#     def predict_proba(self, X):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # ④目的関数（損失関数）\n",
    "    def Loss_function(self,X,y_pred, y):\n",
    "        \"\"\"\n",
    "        目的関数\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        y_pred : self.y_hatの値、テストデータの目的変数　ndarray, shape (n_samples)\n",
    "        y : 実データの目的変数　ndarray, shape (n_samples)\n",
    "        self.theta : パラメータベクトル, shape (n_samples)\n",
    "        self.self.lam : 正則化パラメータ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self.loss_func : 目的関数\n",
    "        self.loss : 訓練用データの目的関数の値がイテレーション回数格納されるndarray\n",
    "        self.val_loss : 検証用データの目的関数の値がイテレーション回数格納されるndarray\n",
    "        \"\"\"\n",
    "        \n",
    "#       #データの数（行の数）\n",
    "        m = len(y_pred)\n",
    "#         #         print(\"m:{}\".format(m))\n",
    "#         #         print(\"type(m):{}\".format(type(m)))\n",
    "#         #         print(\"y_pred:{}\".format(y_pred))\n",
    "#         #         print(\"y:{}\".format(y))\n",
    "        \n",
    "#       #特徴量の数（列の数）\n",
    "        n = len(X[0,:])\n",
    "#       print(\"n:{}\".format(n)) #------検証中--------\n",
    "        \n",
    "\n",
    "        #目的関数のΣi部分を計算\n",
    "        sum_part_i = 0\n",
    "        \n",
    "        for i in range(m):\n",
    "            #print(\"④目的関数self.m:{}.i:{} ,y_pred[i]:{} , y[i]:{}\".format(m,i,y_pred[i],y[i]))# ------検証中--------\n",
    "            \n",
    "            part_i = (-y[i] * math.log(y_pred[i], math.e) - (1 - y[i]) * math.log((1-y_pred[i]), math.e))\n",
    "            sum_part_i += part_i\n",
    "        #print(\"④目的関数 sum_part_i:{}\".format(sum_part_i))# ------検証中--------\n",
    "\n",
    "            \n",
    "        #目的関数のΣj部分を計算\n",
    "        sum_part_j = 0\n",
    "        for j in range(n):\n",
    "            part_j = (self.lam / (2 * m) * (self.theta[j]**2))\n",
    "            sum_part_j += part_i\n",
    "        #print(\"④目的関数 sum_part_j:{}\".format(sum_part_j))# ------検証中--------\n",
    "        \n",
    "        self.loss_func = sum_part_i + sum_part_j\n",
    "\n",
    "        #損失関数を出力する\n",
    "        return self.loss_func\n",
    "    \n",
    "    \n",
    "    #⑤確率を出力するpredict_proba（predictメソッドのリターンself.y_hatを0.1に変換）\n",
    "    def _predict_proba(self):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使い確率を推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "        #\n",
    "        self.y_hat = np.where(self.y_hat < 0.5, 0, 1)\n",
    "        return self.y_hat\n",
    "    \n",
    "    \n",
    "    #【グラフ描画】トレーニングデータとテストデータの損失関数　横軸にイテレーション回数縦軸に損失関数\n",
    "    def Learnig_curve(self):\n",
    "\n",
    "        #self.lossの要素数をndarrayにした。散布図のX座標で使う為\n",
    "        num = np.arange(len(self.loss))\n",
    "        num_val = np.arange(len(self.val_loss))\n",
    "        \n",
    "        #print(\"num:{}\".format(num))\n",
    "        #print(\"self.loss:{}\".format(self.loss))\n",
    "        #print(\"num_val:{}\".format(num))\n",
    "        #print(\"self.val_loss:{}\".format(self.val_loss))\n",
    "\n",
    "        #散布図の描画\n",
    "        plt.scatter(num, self.loss,color = \"red\" )\n",
    "        plt.scatter(num_val, self.val_loss, color = \"blue\")\n",
    "        plt.colorbar()\n",
    "        plt.grid()\n",
    "        return plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # theta = [-2.86590910e-04  8.08181510e-01 -7.85813603e-01]\n",
    "# bbb = np.array([[3] [4] [5]])\n",
    "\n",
    "# print(\"X.size:{}\".format(X.size)) #------検証中--------\n",
    "# # print(\"type(X):{}\".format(type(X))) #------検証中--------\n",
    "# # print(\"X.shape:{}\".format(X.shape)) #------検証中--------\n",
    "# # print(\"X:{}\".format(X)) #------検証中--------\n",
    "\n",
    "# # print(\"theta_2dim.transpose() .size:{}\".format(theta_2dim.transpose() .size)) #------検証中--------\n",
    "# # print(\"type(theta_2dim.transpose() ):{}\".format(type(theta_2dim.transpose() ))) #------検証中--------\n",
    "# # print(\"theta_2dim.transpose() .shape:{}\".format(theta_2dim.transpose() .shape)) #------検証中--------\n",
    "# # print(\"theta_2dim.transpose() :{}\".format(theta_2dim.transpose() )) #------検証中--------\n",
    "        \n",
    "\n",
    "# aaa = X @ bbb\n",
    "# print(aaa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題５】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #----インポート----\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.preprocessing import StandardScaler#標準化のライブラリ\n",
    "\n",
    "# #アヤメインスタンスを生成\n",
    "# heacet = load_iris()\n",
    "\n",
    "# heacet = pd.DataFrame(heacet)#, columns=[\"カラム名１\",\"カラム名２\",\"カラム名３\",\"カラム名４\"]\n",
    "\n",
    "\n",
    "# # #yに関しては\"Species == [0, 1]\"だけのデータを表示させる。（ロジスティック回帰は判定を0.1とする為、目的変数も0.1に変換しないといけない）\n",
    "# # heacet = heacet.query(\"Species == [0, 1]\")\n",
    "\n",
    "\n",
    "# heacet = df.query(\"Species == [0, 1]\").loc[:, [\"sepal_length\", \"petal_length\", \"Species\"]]\n",
    "# heacet.head()\n",
    "\n",
    "\n",
    "\n",
    "# # #DataFrame型変数（X,y）に格納\n",
    "# X = pd.DataFrame(heacet.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n",
    "\n",
    "\n",
    "# y = (pd.DataFrame(heacet.target, columns=[\"Species\"]))\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(y)\n",
    "# #setosa:0・virgicolor:1・virginica:2・sepal_length・petal_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal_length  sepal_width\n",
      "0            5.1          3.5\n",
      "1            4.9          3.0\n",
      "2            4.7          3.2\n",
      "3            4.6          3.1\n",
      "4            5.0          3.6\n",
      "..           ...          ...\n",
      "95           5.7          3.0\n",
      "96           5.7          2.9\n",
      "97           6.2          2.9\n",
      "98           5.1          2.5\n",
      "99           5.7          2.8\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "95    1\n",
      "96    1\n",
      "97    1\n",
      "98    1\n",
      "99    1\n",
      "Name: Species, Length: 100, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#----インポート----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler#標準化のライブラリ\n",
    "\n",
    "\n",
    "\n",
    "# アイリスデータを抽出\n",
    "iris_dataset = load_iris()\n",
    "# .data 部分を抽出し、カラム名も指定する。\n",
    "X = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]).loc[ :  ,  [\"sepal_length\", \"sepal_width\" ] ]\n",
    "\n",
    "# .target 部分を抽出し、カラム名も指定する。\n",
    "y = pd.DataFrame(iris_dataset.target, columns=[\"Species\"])\n",
    "# .concatを使用してXとyを列方向で結合する。\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# .queryで行抽出、locで列抽出する。\n",
    "df_selected = df.query(\"Species == [0, 1]\")\n",
    "\n",
    "# 二度手間だが再度特徴量と目的変数に分けた\n",
    "X = df_selected.iloc[:, :-1]\n",
    "y = df_selected.loc[:, \"Species\"]\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------４つの特徴量を標準化する-----------\n",
    "\n",
    "\n",
    "#データフレームのコピーを作成\n",
    "scaled_features = X.copy()\n",
    "\n",
    "#scalerインスタンスを作成し、StandardScalerクラスのfitメソッドに.valuesでndarrayにしたscaled_featuresを代入\n",
    "scaler = StandardScaler().fit(scaled_features.values) \n",
    "\n",
    "#scalerインスタンスのtransformメソッドにscaled_features.valuesを代入し標準化を実行\n",
    "features = scaler.transform(scaled_features.values) \n",
    "\n",
    "\n",
    "#train_test_split訓練データと検証データに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,y.values , test_size=0.2, random_state=0, shuffle=True\n",
    ")\n",
    "\n",
    "# print(\"X_train:{}\".format(X_train))\n",
    "# print(\" X_test:{}\".format(X_test))\n",
    "# print(\"y_train:{}\".format(y_train))\n",
    "# print(\"y_test:{}\".format(y_test))\n",
    "\n",
    "# print(\"X_train:{}\".format(type(X_train)))\n",
    "# print(\"X_test:{}\".format(type(X_test)))\n",
    "# print(\"y_train:{}\".format(type(y_train)))\n",
    "# print(\"y_test:{}\".format(type(y_test)))\n",
    "\n",
    "# print(\"X_train.shape:{}\".format(type(X_train.shape)))\n",
    "# print(\"X_test.shape:{}\".format(type(X_test.shape)))\n",
    "# print(\"y_train.shape:{}\".format(type(y_train.shape)))\n",
    "# print(\"y_test.shape:{}\".format(type(y_test.shape)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[:,0]:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "X[:,1]:[-0.73768744  1.92487869 -1.20755205  0.35866332  1.76825716 -0.73768744\n",
      " -0.11120129  0.98514947  1.61163562  0.35866332  0.04542025  0.51528486\n",
      "  0.82852793 -1.8340382  -0.73768744 -1.05093052 -1.36417359 -1.05093052\n",
      "  0.04542025 -1.67741667]\n",
      "X.shape③目的変数:(20, 3)\n",
      "theta_2dim.shape③目的変数:(1, 3)\n",
      "X:[[ 1.00000000e+00 -7.37687441e-01  6.31902691e-01]\n",
      " [ 1.00000000e+00  1.92487869e+00  2.09934449e-03]\n",
      " [ 1.00000000e+00 -1.20755205e+00  2.12033793e-01]\n",
      " [ 1.00000000e+00  3.58663321e-01 -6.27704002e-01]\n",
      " [ 1.00000000e+00  1.76825716e+00 -2.07835104e-01]\n",
      " [ 1.00000000e+00 -7.37687441e-01 -1.67737625e+00]\n",
      " [ 1.00000000e+00 -1.11201292e-01  1.68157493e+00]\n",
      " [ 1.00000000e+00  9.85149470e-01 -6.27704002e-01]\n",
      " [ 1.00000000e+00  1.61163562e+00 -6.27704002e-01]\n",
      " [ 1.00000000e+00  3.58663321e-01 -2.07835104e-01]\n",
      " [ 1.00000000e+00  4.54202458e-02 -1.67737625e+00]\n",
      " [ 1.00000000e+00  5.15284858e-01 -1.04757290e+00]\n",
      " [ 1.00000000e+00  8.28527933e-01 -4.17769553e-01]\n",
      " [ 1.00000000e+00 -1.83403820e+00 -2.07835104e-01]\n",
      " [ 1.00000000e+00 -7.37687441e-01  6.31902691e-01]\n",
      " [ 1.00000000e+00 -1.05093052e+00  2.09934449e-03]\n",
      " [ 1.00000000e+00 -1.36417359e+00  1.05177159e+00]\n",
      " [ 1.00000000e+00 -1.05093052e+00  6.31902691e-01]\n",
      " [ 1.00000000e+00  4.54202458e-02  2.31137828e+00]\n",
      " [ 1.00000000e+00 -1.67741667e+00 -4.17769553e-01]]\n",
      "hoge:[0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------【訓練用トレーニングデータの代入】スクラッチ実装の学習-----------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#iris_dataという名前でコンペティションクラスを定義\n",
    "iris_data = ScratchLogisticRegression(n_iteration=1000,alfa = 0.1,lam = 0.1)#なんで学習率は線形回帰はαで、ロジスティック回帰はlrなの？\n",
    "\n",
    "#iris_dataクラスのfitメソッドで訓練用データを学習。パラメータθを算出\n",
    "iris_data.fit(X_train,y_train,X_test, y_test)\n",
    "\n",
    "#iris_dataクラスのpredictで検証用データの予測値y_val_hatを呼び出し\n",
    "y_val_hat = iris_data.predict(X_test)\n",
    "\n",
    "# print(\"y_val_hat:{}\".format(y_val_hat)) #------検証中--------\n",
    "# print(\"y_test:{}\".format(y_test.shape)) #------検証中--------\n",
    "\n",
    "#iris_dataクラスの_predict_probaで検証用データの予測値y_val_hatの0.1データを呼び出し\n",
    "hoge = (iris_data._predict_proba()).reshape(y_test.shape[0],)# reshapeでy_testと同じ形に揃えた\n",
    "print(\"hoge:{}\".format(hoge)) #------検証中--------\n",
    "\n",
    "#学習曲線を描く関数を呼び出し\n",
    "iris_data.Learnig_curve()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.43637999e-02]\n",
      " [9.99418878e-01]\n",
      " [8.72823892e-03]\n",
      " [9.71064498e-01]\n",
      " [9.99440113e-01]\n",
      " [9.27093154e-01]\n",
      " [6.73857581e-03]\n",
      " [9.97060832e-01]\n",
      " [9.99708461e-01]\n",
      " [9.07387991e-01]\n",
      " [9.95655859e-01]\n",
      " [9.95144792e-01]\n",
      " [9.90365834e-01]\n",
      " [2.97475490e-03]\n",
      " [1.43637999e-02]\n",
      " [2.82364576e-02]\n",
      " [4.20725086e-04]\n",
      " [4.56274808e-03]\n",
      " [1.90462567e-03]\n",
      " [9.75002195e-03]]\n",
      "[0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "acc : 1.0\n",
      "precision : 1.0\n",
      "recall : 1.0\n",
      "f1 : 1.0\n",
      "confusion matrix \n",
      " [[10  0]\n",
      " [ 0 10]]\n"
     ]
    }
   ],
   "source": [
    "# 学習結果の成績を行う関数\n",
    "#iris_dataクラスの_predict_probaで検証用データの予測値y_val_hatの0.1データを呼び出し\n",
    "hoge = (iris_data._predict_proba()).reshape(y_test.shape[0],)# reshapeでy_testと同じ形に揃えた\n",
    "def evaluate(y_pred, y_test):\n",
    "    \"\"\"\n",
    "    y_val_hat, y_testの評価指標を計算する\n",
    "    \"\"\"\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "    return acc, precision, recall, f1, confusion\n",
    "\n",
    "print(y_val_hat)\n",
    "print(y_test)\n",
    "\n",
    "acc, precision, recall, f1, confusion = evaluate(hoge, y_test)\n",
    "\n",
    "print(\"acc : {}\\nprecision : {}\\nrecall : {}\\nf1 : {}\\nconfusion matrix \\n {}\".format(*evaluate(y_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定領域の可視化を行う関数\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    print(\"mesh.shape:{}\".format(mesh.shape)) #------検証中--------\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】決定領域の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh.shape:(237524, 2)\n",
      "X[:,0]:[1. 1. 1. ... 1. 1. 1.]\n",
      "X[:,1]:[-2.3340382 -2.3240382 -2.3140382 ...  2.3959618  2.4059618  2.4159618]\n",
      "X.shape③目的変数:(237524, 3)\n",
      "theta_2dim.shape③目的変数:(1, 3)\n",
      "X:[[ 1.         -2.3340382  -2.17737625]\n",
      " [ 1.         -2.3240382  -2.17737625]\n",
      " [ 1.         -2.3140382  -2.17737625]\n",
      " ...\n",
      " [ 1.          2.3959618   2.80262375]\n",
      " [ 1.          2.4059618   2.80262375]\n",
      " [ 1.          2.4159618   2.80262375]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# X = df.query(\"Species == [0, 1]\").loc[:, [\"sepal_length\", \"sepal_width\"]]\n",
    "# X = X.values\n",
    "# y = (df.query(\"Species == [0, 1]\")[\"Species\"]).values\n",
    "\n",
    "\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)\n",
    "# print(type(X_test))\n",
    "# print(type(y_test))\n",
    "# print(X_test)\n",
    "# print(y_test)\n",
    "\n",
    "#決定領域の可視化関数呼び出し\n",
    "decision_region(X_test,y_test,iris_data, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハマったポイント\n",
    "\n",
    "・バイアス化を最初クラスの外に書いたらひな型の領域を描く関数が機能せず、中に書いたらfitとpredictの両方の関数にバイアス化する\n",
    "コードが必要でそれに気づかず時間がかかった。クラスの中のメソッド同士でもクラスの外でメソッドを呼び出す場合fitのXなどの変数をpredictで使うことはできない。\n",
    "\n",
    "・クラスの中のメソッドをクラス内とクラス外の両方で使うとき、同じメソッドを２つ作る。クラス外から呼び出すときはクラス内の変数が使えない為\n",
    "フィットメソッドにバイアス追加を付けて\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
