{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#インポート\n",
    "###################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "X_train[0]:[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "------検証中---------\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#データセットをダウンロード\n",
    "###################\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(\"X_train[0]:{}\".format(X_train[0])) #------検証中--------\n",
    "\n",
    "print(\"------検証中---------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "X_test:[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#平滑化(1, 28, 28)の各画像を(1, 784)に変換\n",
    "###################\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "print(\"X_train:{}\".format(X_train)) #------検証中--------\n",
    "print(\"X_test:{}\".format(X_test)) #------検証中--------\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#前処理データをフロート型にして255で割ることで正規化\n",
    "###################\n",
    "\n",
    "#データの型を変換\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "\n",
    "#データを0から1の数字に変換\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n",
      "y_train_one_hot[0]:[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#ｙの値の0-9をone-hot表現に変換\n",
    "###################\n",
    "\n",
    "#encでワンホットエンコーダをインスタンス化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#y-trainとy-testをone-hot表現に変換（np.newaxisで次元を追加している）\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "#y_train.shape：６００００個の０から９の数字(画像データではない）\n",
    "print(y_train.shape) # (60000,)\n",
    "\n",
    "#y_train_one_hot.shape：６００００個の０から９を表す0と1のデータ\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "print(\"y_train_one_hot[0]:{}\".format(y_train_one_hot[0])) #------検証中--------\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n",
      "[6 3 7 ... 3 1 7]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#Xとｙのトレーニングデータを分割\n",
    "###################\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) #\n",
    "print(y_val) #\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "###################\n",
    "#【問題1】全結合層のクラス化\n",
    "###################\n",
    "class FC:\n",
    "    \"\"\"全結合層\"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        initializer : 初期化インスタンス\n",
    "        optimizer : 勾配更新手法\n",
    "        \"\"\"\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "\n",
    "        # 初期化インスタンスの関数実行\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "\n",
    "        # 最適化インスタンス\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # 勾配更新の際に使用（AdaGradのみ）\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        # 逆伝播時に使用\n",
    "        self.Z = X\n",
    "        # 順伝播計算部分本体\n",
    "        self.A = X @ self.W + self.B\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 前の層から逆伝播してきた値（活性化関数の逆伝播の値が入ってくる）\n",
    "        \"\"\"\n",
    "        # バイアス項の勾配\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        # バイアス項以外の勾配\n",
    "        self.dW = self.Z.T @ dA\n",
    "        # 逆伝播させる値\n",
    "        self.dZ = dA @ self.W.T\n",
    "        # 重み更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "###################\n",
    "#問題2　初期化方法のクラス化\n",
    "###################\n",
    "\n",
    "\n",
    "class SimpleInitializer:\n",
    "    \"\"\"各種重みの初期化\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : 重みの初期化の際のガウス分布の標準偏差\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "###################\n",
    "#問題3　最適化手法のクラス化\n",
    "###################\n",
    "\n",
    "\n",
    "class SGD:\n",
    "    \"\"\"勾配更新手法\"\"\"\n",
    "    def __init__(self, lr):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : 学習率\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : FCクラスのインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / len(layer.Z)\n",
    "        return layer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "###################\n",
    "#問題4　活性化関数のクラス化\n",
    "###################\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"シグモイド関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = 1 / (1 + np.exp(-self.A))\n",
    "        return Z\n",
    "\n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A)))**2)\n",
    "        return dA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \"\"\"tanh関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "\n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
    "        return dA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \"\"\"Softmax関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "\n",
    "    def backward(self, Z, y):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 出力値\n",
    "        y : 正解データ\n",
    "        \"\"\"\n",
    "        # 逆伝播の値\n",
    "        dA = Z - y\n",
    "        # 損失\n",
    "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
    "        return dA, loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "###################\n",
    "#問題5　ReLUクラスの作成\n",
    "###################\n",
    "\n",
    "class ReLU:\n",
    "    \"\"\"ReLU関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "\n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "###################\n",
    "#問題6　重みの初期値\n",
    "###################\n",
    "\n",
    "class XavierInitializer:\n",
    "    \"\"\"Xavierの初期化クラス\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : 使用されていない\n",
    "\n",
    "        Overview\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        _ = sigma\n",
    "\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"Heの初期化クラス\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        _ = sigma\n",
    "\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "###################\n",
    "#問題7　最適化手法\n",
    "###################\n",
    "\n",
    "\n",
    "class AdaGrad:\n",
    "    \"\"\"最適化手法（AdaGrad）\"\"\"\n",
    "    def __init__(self, lr):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : 学習率\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : layerインスタンス\n",
    "        \"\"\"\n",
    "        layer.HW += layer.dW * layer.dW\n",
    "        layer.HB += layer.dB * layer.dB\n",
    "        delta = 1e-7 # 0割エラー防止のため\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
    "        return layer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "###################\n",
    "#問題8　クラスの完成\n",
    "###################\n",
    "\n",
    "class GetMiniBatch:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        \"\"\"通常のコンストラクタと同様の働き\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数（画像の1次元データ）\n",
    "        y : 目的変数（ラベル）\n",
    "        batch_size : 必要なミニバッチのデータ数\n",
    "        seed : ランダムシード固定\n",
    "        \"\"\"\n",
    "        # ランダムシードの固定（学習ごとに同じ生成順）\n",
    "        np.random.seed(seed)\n",
    "        # バッチ数のメンバ変数\n",
    "        self.batch_size = batch_size\n",
    "        # データ全体の長さ分のインデックスをランダムに並べ替え\n",
    "        # np.random.permutation:配列をランダムに並べ替え\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        # 並べ替えたインデックスと同じ順番で説明変数と目的変数を並べ替え\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        # データ数をバッチ数で割って、何回呼び出せば、全データを学習したことになるかの判定\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 何回目の呼び出しか\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # 全データを学習すればストップ\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        # 並び変えた_X,_yの何番目のインデックスを採用するか\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        # returnする前にカウンタに+1しておく\n",
    "        self._counter += 1\n",
    "        # 説明変数と目的変数を返す\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "\n",
    "    def __init__(self,batch_size=20,n_features=784,n_nodes1 =400,n_nodes2 = 200,n_output =10,lr =0.005,epoch=10,sigma=0.02,optimizer=SGD, initializer=HeInitializer,activater=ReLU,output_activater=Softmax,verbose=True):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : バッチサイズ（default:20)\n",
    "        n_features : 説明変数の数（default:784)\n",
    "        n_nodes1 : 前の層のノード数（default:400)\n",
    "        n_nodes2 : 当該層のノード数（default:200)\n",
    "        n_output : 出力層のノード数（default:10)\n",
    "        sigma : 初期化時のパラメータ（default:0.02)\n",
    "        lr : 学習率（default:0.005)\n",
    "        verbose : 計算過程の出力（default:True)\n",
    "        epoch : 学習回数（default:10)\n",
    "        optimizer : 最適化手法（default:SGD)\n",
    "        initializer : 初期化方法（default:HeInitializer）\n",
    "        activater : 活性化関数（default:ReLU）\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.optimizer = optimizer\n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer\n",
    "        self.activater = activater\n",
    "        self.output_activater = output_activater\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"学習\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        y : 訓練データの目的変数\n",
    "        X_val : 評価データの説明変数\n",
    "        y_val : 評価データの目的変数\n",
    "        \"\"\"\n",
    "        # lossの記録用配列\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "        # 最適化手法の初期化\n",
    "        optimizer = self.optimizer(self.lr)\n",
    "        # 各層の初期化\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
    "        self.activation1 = self.activater()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
    "        self.activation2 = self.activater()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
    "        self.activation3 = self.output_activater()\n",
    "\n",
    "        # 学習回数分ループ\n",
    "        for i in range(self.epoch):\n",
    "            # ミニバッチイテレータ生成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            # ミニバッチイテレータループ\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                ## 順伝播\n",
    "                # 1層目\n",
    "                A1 = self.FC1.forward(mini_X)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                # 2層目\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                # 3層目\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "\n",
    "                ## 逆伝播\n",
    "                dA3, loss = self.activation3.backward(Z3, mini_y)\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1)\n",
    "\n",
    "            # 過程出力\n",
    "            if self.verbose:\n",
    "                ## 順伝播\n",
    "                # 1層目\n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                # 2層目\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                # 3層目\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                # 損失計算と記録\n",
    "                loss = self.activation3.backward(Z3, y)[1]\n",
    "                self.loss_train.append(loss)\n",
    "                print('epoch:%d train_loss:%f'%(i,loss))\n",
    "                # 評価データ見る\n",
    "                if X_val is not None:\n",
    "                    ## 順伝播\n",
    "                    # 1層目\n",
    "                    A1 = self.FC1.forward(X_val)\n",
    "                    Z1 = self.activation1.forward(A1)\n",
    "                    # 2層目\n",
    "                    A2 = self.FC2.forward(Z1)\n",
    "                    Z2 = self.activation2.forward(A2)\n",
    "                    # 3層目\n",
    "                    A3 = self.FC3.forward(Z2)\n",
    "                    Z3 = self.activation3.forward(A3)\n",
    "                    # 損失計算と記録\n",
    "                    self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        ## 順伝播\n",
    "        # 1層目\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        # 2層目\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        # 3層目\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        # 最も大きいインデックスを採用\n",
    "        return np.argmax(Z3, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:2.304134\n",
      "epoch:1 train_loss:2.284676\n",
      "epoch:2 train_loss:2.268171\n",
      "epoch:3 train_loss:2.255812\n",
      "epoch:4 train_loss:2.244088\n",
      "epoch:5 train_loss:2.232042\n",
      "epoch:6 train_loss:2.223271\n",
      "epoch:7 train_loss:2.213170\n",
      "epoch:8 train_loss:2.202052\n",
      "epoch:9 train_loss:2.193318\n",
      "epoch:10 train_loss:2.183267\n",
      "epoch:11 train_loss:2.173420\n",
      "epoch:12 train_loss:2.167817\n",
      "epoch:13 train_loss:2.154404\n",
      "epoch:14 train_loss:2.146236\n",
      "epoch:15 train_loss:2.138715\n",
      "epoch:16 train_loss:2.127486\n",
      "epoch:17 train_loss:2.116786\n",
      "epoch:18 train_loss:2.109711\n",
      "epoch:19 train_loss:2.098999\n",
      "epoch:20 train_loss:2.088091\n",
      "epoch:21 train_loss:2.079391\n",
      "epoch:22 train_loss:2.070956\n",
      "epoch:23 train_loss:2.058478\n",
      "epoch:24 train_loss:2.050403\n",
      "epoch:25 train_loss:2.038642\n",
      "epoch:26 train_loss:2.032555\n",
      "epoch:27 train_loss:2.017881\n",
      "epoch:28 train_loss:2.007003\n",
      "epoch:29 train_loss:1.994378\n",
      "epoch:30 train_loss:1.981007\n",
      "epoch:31 train_loss:1.969949\n",
      "epoch:32 train_loss:1.962599\n",
      "epoch:33 train_loss:1.952041\n",
      "epoch:34 train_loss:1.934071\n",
      "epoch:35 train_loss:1.925223\n",
      "epoch:36 train_loss:1.908212\n",
      "epoch:37 train_loss:1.900194\n",
      "epoch:38 train_loss:1.887602\n",
      "epoch:39 train_loss:1.874777\n",
      "epoch:40 train_loss:1.857793\n",
      "epoch:41 train_loss:1.843954\n",
      "epoch:42 train_loss:1.826878\n",
      "epoch:43 train_loss:1.814679\n",
      "epoch:44 train_loss:1.797651\n",
      "epoch:45 train_loss:1.783203\n",
      "epoch:46 train_loss:1.769309\n",
      "epoch:47 train_loss:1.754723\n",
      "epoch:48 train_loss:1.742932\n",
      "epoch:49 train_loss:1.720302\n",
      "epoch:50 train_loss:1.712474\n",
      "epoch:51 train_loss:1.692529\n",
      "epoch:52 train_loss:1.670192\n",
      "epoch:53 train_loss:1.655698\n",
      "epoch:54 train_loss:1.643259\n",
      "epoch:55 train_loss:1.626023\n",
      "epoch:56 train_loss:1.604941\n",
      "epoch:57 train_loss:1.585905\n",
      "epoch:58 train_loss:1.570534\n",
      "epoch:59 train_loss:1.547417\n",
      "epoch:60 train_loss:1.538356\n",
      "epoch:61 train_loss:1.516791\n",
      "epoch:62 train_loss:1.488487\n",
      "epoch:63 train_loss:1.471751\n",
      "epoch:64 train_loss:1.455749\n",
      "epoch:65 train_loss:1.439831\n",
      "epoch:66 train_loss:1.412696\n",
      "epoch:67 train_loss:1.411782\n",
      "epoch:68 train_loss:1.370808\n",
      "epoch:69 train_loss:1.357498\n",
      "epoch:70 train_loss:1.332443\n",
      "epoch:71 train_loss:1.335396\n",
      "epoch:72 train_loss:1.293486\n",
      "epoch:73 train_loss:1.280985\n",
      "epoch:74 train_loss:1.253613\n",
      "epoch:75 train_loss:1.263734\n",
      "epoch:76 train_loss:1.221143\n",
      "epoch:77 train_loss:1.195481\n",
      "epoch:78 train_loss:1.169514\n",
      "epoch:79 train_loss:1.160529\n",
      "epoch:80 train_loss:1.138402\n",
      "epoch:81 train_loss:1.111582\n",
      "epoch:82 train_loss:1.087041\n",
      "epoch:83 train_loss:1.082864\n",
      "epoch:84 train_loss:1.071192\n",
      "epoch:85 train_loss:1.030071\n",
      "epoch:86 train_loss:1.000358\n",
      "epoch:87 train_loss:0.994025\n",
      "epoch:88 train_loss:0.974292\n",
      "epoch:89 train_loss:0.960782\n",
      "epoch:90 train_loss:0.950397\n",
      "epoch:91 train_loss:0.904759\n",
      "epoch:92 train_loss:0.898430\n",
      "epoch:93 train_loss:0.879413\n",
      "epoch:94 train_loss:0.851111\n",
      "epoch:95 train_loss:0.833069\n",
      "epoch:96 train_loss:0.801193\n",
      "epoch:97 train_loss:0.787144\n",
      "epoch:98 train_loss:0.772404\n",
      "epoch:99 train_loss:0.748559\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################\n",
    "#問題9　学習と推定\n",
    "###################\n",
    "\n",
    "\n",
    "dnn = ScratchDeepNeuralNetrowkClassifier(epoch=100)\n",
    "\n",
    "dnn.fit(X_train[:4000], y_train_one_hot[:4000], X_val[:2000], y_test_one_hot[:2000])\n",
    "\n",
    "\n",
    "pred = dnn.predict(X_val)\n",
    "accuracy_score(y_val, pred)\n",
    "\n",
    "\n",
    "plt.plot(list(range(1, dnn.epoch+1)), dnn.loss_train, label='train')\n",
    "plt.plot(list(range(1, dnn.epoch+1)), dnn.loss_val, label='test')\n",
    "plt.legend()\n",
    "plt.xticks(list(range(1, dnn.epoch+1)));\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}