{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#インポート\n",
    "###################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor, ARDRegression, RidgeCV\n",
    "from sklearn.linear_model import TheilSenRegressor, RANSACRegressor, HuberRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler#標準化のライブラリ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n...          ...       ...  ...      ...    ...    ...         ...     ...   \n1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n0         2   2008        WD         Normal     208500  \n1         5   2007        WD         Normal     181500  \n2         9   2008        WD         Normal     223500  \n3         2   2006        WD        Abnorml     140000  \n4        12   2008        WD         Normal     250000  \n...     ...    ...       ...            ...        ...  \n1455      8   2007        WD         Normal     175000  \n1456      2   2010        WD         Normal     210000  \n1457      5   2010        WD         Normal     266500  \n1458      4   2010        WD         Normal     142125  \n1459      6   2008        WD         Normal     147500  \n\n[1460 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 81 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n529    530          20       RL          NaN    32668   Pave   NaN      IR1   \n491    492          50       RL         79.0     9490   Pave   NaN      Reg   \n459    460          50       RL          NaN     7015   Pave   NaN      IR1   \n279    280          60       RL         83.0    10005   Pave   NaN      Reg   \n655    656         160       RM         21.0     1680   Pave   NaN      Reg   \n1013  1014          30       RM         60.0     7200   Pave   NaN      Reg   \n1403  1404          20       RL         49.0    15256   Pave   NaN      IR1   \n601    602          50       RM         50.0     9000   Pave   NaN      Reg   \n1182  1183          60       RL        160.0    15623   Pave   NaN      IR1   \n687    688         160       FV          NaN     5105   Pave   NaN      IR2   \n1317  1318         120       FV         47.0     4230   Pave  Pave      Reg   \n1003  1004          90       RL          NaN    11500   Pave   NaN      IR1   \n1300  1301          60       RL          NaN    10762   Pave   NaN      IR1   \n1392  1393          85       RL         68.0     7838   Pave   NaN      Reg   \n1014  1015          20       RL         60.0    11664   Pave   NaN      Reg   \n254    255          20       RL         70.0     8400   Pave   NaN      Reg   \n1322  1323          60       RL        107.0    10186   Pave   NaN      IR1   \n89      90          20       RL         60.0     8070   Pave   NaN      Reg   \n31      32          20       RL          NaN     8544   Pave   NaN      IR1   \n482    483          70       RM         50.0     2500   Pave  Pave      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n529          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n491          Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n459          Bnk    AllPub  ...        0    NaN    NaN         NaN       0   \n279          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n655          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1013         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1403         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n601          Bnk    AllPub  ...        0    NaN    NaN         NaN       0   \n1182         Lvl    AllPub  ...      555     Ex  MnPrv         NaN       0   \n687          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1317         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1003         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1300         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1392         Lvl    AllPub  ...        0    NaN   MnWw         NaN       0   \n1014         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n254          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1322         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n89           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n31           Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n482          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n529       3   2007        WD         Alloca     200624  \n491       8   2006        WD         Normal     133000  \n459       7   2009        WD         Normal     110000  \n279       3   2008        WD         Normal     192000  \n655       3   2010        WD         Family      88000  \n1013      6   2009        WD         Normal      85000  \n1403      8   2007        WD         Normal     282922  \n601      12   2007        WD         Normal     141000  \n1182      7   2007        WD        Abnorml     745000  \n687       3   2007        WD         Normal     148800  \n1317      4   2007       New        Partial     208900  \n1003      6   2007        WD         Normal     136905  \n1300      5   2009        WD         Normal     225000  \n1392     12   2006        WD         Normal     123000  \n1014     11   2007        WD         Normal     119200  \n254       6   2010        WD         Normal     145000  \n1322      6   2010        WD         Normal     190000  \n89        8   2007        WD         Normal     123600  \n31        6   2008        WD         Normal     149350  \n482       6   2009        WD         Normal     155000  \n\n[20 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>529</th>\n      <td>530</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>32668</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Alloca</td>\n      <td>200624</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>492</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>79.0</td>\n      <td>9490</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>133000</td>\n    </tr>\n    <tr>\n      <th>459</th>\n      <td>460</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>7015</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Bnk</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>110000</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>280</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>83.0</td>\n      <td>10005</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>192000</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>656</td>\n      <td>160</td>\n      <td>RM</td>\n      <td>21.0</td>\n      <td>1680</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Family</td>\n      <td>88000</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>1014</td>\n      <td>30</td>\n      <td>RM</td>\n      <td>60.0</td>\n      <td>7200</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>85000</td>\n    </tr>\n    <tr>\n      <th>1403</th>\n      <td>1404</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>49.0</td>\n      <td>15256</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>282922</td>\n    </tr>\n    <tr>\n      <th>601</th>\n      <td>602</td>\n      <td>50</td>\n      <td>RM</td>\n      <td>50.0</td>\n      <td>9000</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Bnk</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>141000</td>\n    </tr>\n    <tr>\n      <th>1182</th>\n      <td>1183</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>160.0</td>\n      <td>15623</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>555</td>\n      <td>Ex</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>745000</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>688</td>\n      <td>160</td>\n      <td>FV</td>\n      <td>NaN</td>\n      <td>5105</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR2</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>148800</td>\n    </tr>\n    <tr>\n      <th>1317</th>\n      <td>1318</td>\n      <td>120</td>\n      <td>FV</td>\n      <td>47.0</td>\n      <td>4230</td>\n      <td>Pave</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2007</td>\n      <td>New</td>\n      <td>Partial</td>\n      <td>208900</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>1004</td>\n      <td>90</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>11500</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>136905</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <td>1301</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>10762</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>225000</td>\n    </tr>\n    <tr>\n      <th>1392</th>\n      <td>1393</td>\n      <td>85</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>7838</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnWw</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>123000</td>\n    </tr>\n    <tr>\n      <th>1014</th>\n      <td>1015</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>11664</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>119200</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>255</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>70.0</td>\n      <td>8400</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>145000</td>\n    </tr>\n    <tr>\n      <th>1322</th>\n      <td>1323</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>107.0</td>\n      <td>10186</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>190000</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>90</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>8070</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>123600</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>8544</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>149350</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>483</td>\n      <td>70</td>\n      <td>RM</td>\n      <td>50.0</td>\n      <td>2500</td>\n      <td>Pave</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>155000</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 81 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n529    530          20       RL          NaN    32668   Pave   NaN      IR1   \n491    492          50       RL         79.0     9490   Pave   NaN      Reg   \n459    460          50       RL          NaN     7015   Pave   NaN      IR1   \n279    280          60       RL         83.0    10005   Pave   NaN      Reg   \n655    656         160       RM         21.0     1680   Pave   NaN      Reg   \n1013  1014          30       RM         60.0     7200   Pave   NaN      Reg   \n1403  1404          20       RL         49.0    15256   Pave   NaN      IR1   \n601    602          50       RM         50.0     9000   Pave   NaN      Reg   \n1182  1183          60       RL        160.0    15623   Pave   NaN      IR1   \n687    688         160       FV          NaN     5105   Pave   NaN      IR2   \n1317  1318         120       FV         47.0     4230   Pave  Pave      Reg   \n1003  1004          90       RL          NaN    11500   Pave   NaN      IR1   \n1300  1301          60       RL          NaN    10762   Pave   NaN      IR1   \n1392  1393          85       RL         68.0     7838   Pave   NaN      Reg   \n1014  1015          20       RL         60.0    11664   Pave   NaN      Reg   \n254    255          20       RL         70.0     8400   Pave   NaN      Reg   \n1322  1323          60       RL        107.0    10186   Pave   NaN      IR1   \n89      90          20       RL         60.0     8070   Pave   NaN      Reg   \n31      32          20       RL          NaN     8544   Pave   NaN      IR1   \n482    483          70       RM         50.0     2500   Pave  Pave      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n529          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n491          Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n459          Bnk    AllPub  ...        0    NaN    NaN         NaN       0   \n279          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n655          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1013         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1403         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n601          Bnk    AllPub  ...        0    NaN    NaN         NaN       0   \n1182         Lvl    AllPub  ...      555     Ex  MnPrv         NaN       0   \n687          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1317         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1003         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1300         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1392         Lvl    AllPub  ...        0    NaN   MnWw         NaN       0   \n1014         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n254          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1322         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n89           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n31           Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n482          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n529       3   2007        WD         Alloca     200624  \n491       8   2006        WD         Normal     133000  \n459       7   2009        WD         Normal     110000  \n279       3   2008        WD         Normal     192000  \n655       3   2010        WD         Family      88000  \n1013      6   2009        WD         Normal      85000  \n1403      8   2007        WD         Normal     282922  \n601      12   2007        WD         Normal     141000  \n1182      7   2007        WD        Abnorml     745000  \n687       3   2007        WD         Normal     148800  \n1317      4   2007       New        Partial     208900  \n1003      6   2007        WD         Normal     136905  \n1300      5   2009        WD         Normal     225000  \n1392     12   2006        WD         Normal     123000  \n1014     11   2007        WD         Normal     119200  \n254       6   2010        WD         Normal     145000  \n1322      6   2010        WD         Normal     190000  \n89        8   2007        WD         Normal     123600  \n31        6   2008        WD         Normal     149350  \n482       6   2009        WD         Normal     155000  \n\n[20 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>529</th>\n      <td>530</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>32668</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Alloca</td>\n      <td>200624</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>492</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>79.0</td>\n      <td>9490</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>133000</td>\n    </tr>\n    <tr>\n      <th>459</th>\n      <td>460</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>7015</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Bnk</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>110000</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>280</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>83.0</td>\n      <td>10005</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>192000</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>656</td>\n      <td>160</td>\n      <td>RM</td>\n      <td>21.0</td>\n      <td>1680</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Family</td>\n      <td>88000</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>1014</td>\n      <td>30</td>\n      <td>RM</td>\n      <td>60.0</td>\n      <td>7200</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>85000</td>\n    </tr>\n    <tr>\n      <th>1403</th>\n      <td>1404</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>49.0</td>\n      <td>15256</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>282922</td>\n    </tr>\n    <tr>\n      <th>601</th>\n      <td>602</td>\n      <td>50</td>\n      <td>RM</td>\n      <td>50.0</td>\n      <td>9000</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Bnk</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>141000</td>\n    </tr>\n    <tr>\n      <th>1182</th>\n      <td>1183</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>160.0</td>\n      <td>15623</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>555</td>\n      <td>Ex</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>745000</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>688</td>\n      <td>160</td>\n      <td>FV</td>\n      <td>NaN</td>\n      <td>5105</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR2</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>148800</td>\n    </tr>\n    <tr>\n      <th>1317</th>\n      <td>1318</td>\n      <td>120</td>\n      <td>FV</td>\n      <td>47.0</td>\n      <td>4230</td>\n      <td>Pave</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2007</td>\n      <td>New</td>\n      <td>Partial</td>\n      <td>208900</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>1004</td>\n      <td>90</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>11500</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>136905</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <td>1301</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>10762</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>225000</td>\n    </tr>\n    <tr>\n      <th>1392</th>\n      <td>1393</td>\n      <td>85</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>7838</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnWw</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>123000</td>\n    </tr>\n    <tr>\n      <th>1014</th>\n      <td>1015</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>11664</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>119200</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>255</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>70.0</td>\n      <td>8400</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>145000</td>\n    </tr>\n    <tr>\n      <th>1322</th>\n      <td>1323</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>107.0</td>\n      <td>10186</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>190000</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>90</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>8070</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>123600</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>8544</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>149350</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>483</td>\n      <td>70</td>\n      <td>RM</td>\n      <td>50.0</td>\n      <td>2500</td>\n      <td>Pave</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>155000</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 81 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[2515 2515]\n",
      " [ 990  990]\n",
      " [1314 1314]\n",
      " [1578 1578]]\n",
      "y_train:[[745000]\n",
      " [ 85000]\n",
      " [136905]\n",
      " [192000]\n",
      " [149350]\n",
      " [190000]\n",
      " [123000]\n",
      " [110000]\n",
      " [148800]\n",
      " [155000]\n",
      " [ 88000]\n",
      " [225000]\n",
      " [141000]\n",
      " [208900]\n",
      " [119200]\n",
      " [282922]]\n",
      "y_test:[[200624]\n",
      " [123600]\n",
      " [145000]\n",
      " [133000]]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#csvファイルを呼び出し\n",
    "###################\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "display(df)\n",
    "\n",
    "#データ数の絞り込み\n",
    "df = df.sample(n=20, random_state=0)\n",
    "display(df)\n",
    "\n",
    "#目的変数と特徴量の絞り込み\n",
    "X = (df.loc[ :  ,  [ 'GrLivArea',  'GrLivArea' ] ]).values\n",
    "y = (df.loc[ :  ,  [ 'SalePrice' ] ]).values\n",
    "display(df)\n",
    "\n",
    "#csvファイルを呼び出し\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train:{}\".format(X_train)) #------検証中--------\n",
    "print(\"X_test:{}\".format(X_test)) #------検証中--------\n",
    "print(\"y_train:{}\".format(y_train)) #------検証中--------\n",
    "print(\"y_test:{}\".format(y_test)) #------検証中--------\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_LR:(4, 1)\n",
      "prediction_SVR:(4,)\n",
      "prediction_DT:(4,)\n",
      "y_pred:[270888.0394931   86205.44465287 176026.36972057 162738.51236832]\n",
      "ブレンディング:2045600687.853942\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#【問題1】ブレンディングのスクラッチ実装\n",
    "###################\n",
    "\n",
    "\n",
    "#------------①LinearRegression(),------------\n",
    "LR = LinearRegression().fit(X_train,y_train)\n",
    "prediction_LR = LR.predict(X_test)\n",
    "print(\"prediction_LR:{}\".format(prediction_LR.shape)) #------検証中--------\n",
    "\n",
    "#-------------②SVR()-----------\n",
    "SVR = SVR().fit(X_train,y_train)\n",
    "prediction_SVR = SVR.predict(X_test)\n",
    "print(\"prediction_SVR:{}\".format(prediction_SVR.shape)) #------検証中--------\n",
    "\n",
    "#------------③DecisionTreeRegressor()------------\n",
    "DT = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "prediction_DT = DT.predict(X_test)\n",
    "print(\"prediction_DT:{}\".format(prediction_DT.shape)) #------検証中--------\n",
    "\n",
    "\n",
    "# 予測値の平均値をとる\n",
    "y_pred = np.mean([prediction_LR.reshape(len(prediction_LR),),prediction_DT],axis=0)\n",
    "print(\"y_pred:{}\".format(y_pred)) #------検証中--------\n",
    "\n",
    "# MSEの算出\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "\n",
    "print(\"ブレンディング:{}\".format(mse)) #------検証中--------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0\n",
      "X_bagging.shape:(16, 2)\n",
      "_X.shape:(4, 2)\n",
      "y_bagging.shape:(16, 1)\n",
      "_y.shape:(4, 1)\n",
      "[DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "i:1\n",
      "X_bagging.shape:(16, 2)\n",
      "_X.shape:(4, 2)\n",
      "y_bagging.shape:(16, 1)\n",
      "_y.shape:(4, 1)\n",
      "[DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "i:2\n",
      "X_bagging.shape:(16, 2)\n",
      "_X.shape:(4, 2)\n",
      "y_bagging.shape:(16, 1)\n",
      "_y.shape:(4, 1)\n",
      "[DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "i:3\n",
      "X_bagging.shape:(16, 2)\n",
      "_X.shape:(4, 2)\n",
      "y_bagging.shape:(16, 1)\n",
      "_y.shape:(4, 1)\n",
      "[DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "i:4\n",
      "X_bagging.shape:(16, 2)\n",
      "_X.shape:(4, 2)\n",
      "y_bagging.shape:(16, 1)\n",
      "_y.shape:(4, 1)\n",
      "[DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "model:DecisionTreeRegressor()\n",
      "_prediction:[155000. 119200. 282922. 282922.]\n",
      "prediction:[155000. 119200. 282922. 282922.]\n",
      "\n",
      "\n",
      "model:DecisionTreeRegressor()\n",
      "_prediction:[225000.  85000. 148800. 225000.]\n",
      "prediction:[380000. 204200. 431722. 507922.]\n",
      "\n",
      "\n",
      "model:DecisionTreeRegressor()\n",
      "_prediction:[192000. 123000. 136905. 136905.]\n",
      "prediction:[572000. 327200. 568627. 644827.]\n",
      "\n",
      "\n",
      "model:DecisionTreeRegressor()\n",
      "_prediction:[192000. 149350. 149350. 155000.]\n",
      "prediction:[764000. 476550. 717977. 799827.]\n",
      "\n",
      "\n",
      "model:DecisionTreeRegressor()\n",
      "_prediction:[192000. 141000. 141000. 136905.]\n",
      "prediction:[956000. 617550. 858977. 936732.]\n",
      "\n",
      "\n",
      "決定木:940086132.5299999\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#【問題2】バギングのスクラッチ実装\n",
    "###################\n",
    "\n",
    "# 作成するデータセットの個数\n",
    "n = 5\n",
    "\n",
    "# 学習したモデルのインスタンスを格納するリスト\n",
    "models = []\n",
    "\n",
    "for i in range(n):\n",
    "    # 訓練データをさらにランダムにｎ回分割\n",
    "    X_bagging, _X, y_bagging, _y = train_test_split(X_train,y_train,train_size=0.2,shuffle=True)\n",
    "    print(\"i:{}\".format(i)) #------検証中--------\n",
    "    print(\"X_bagging.shape:{}\".format(X_train.shape)) #------検証中--------\n",
    "    print(\"_X.shape:{}\".format(X_test.shape)) #------検証中--------\n",
    "    print(\"y_bagging.shape:{}\".format(y_train.shape)) #------検証中--------\n",
    "    print(\"_y.shape:{}\".format(y_test.shape)) #------検証中--------\n",
    "\n",
    "    # モデルの定義\n",
    "    model = DecisionTreeRegressor()\n",
    "    # 学習\n",
    "    model.fit(X_bagging,y_bagging)\n",
    "    # モデルを記録\n",
    "    models.append(model)\n",
    "    print(models)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 予測値の初期値\n",
    "prediction = np.zeros(len(X_test))#prediction += _predictionで配列同士を足すので最初から配列の形を作っておいたほうが足せる。forだと値が入っていない場合次元が合わなくてエラーになる。\n",
    "\n",
    "# 記録してあるモデルでループ\n",
    "for model in models:\n",
    "    print(\"model:{}\".format(model)) #------検証中--------\n",
    "    # 予測値の算出\n",
    "    _prediction = model.predict(X_test)\n",
    "    print(\"_prediction:{}\".format(_prediction)) #------検証中--------\n",
    "    # 予測値を加算していく\n",
    "    prediction += _prediction\n",
    "    print(\"prediction:{}\".format(prediction)) #------検証中--------\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 加算していった予測値をn（モデル数）で割ることで平均値を算出\n",
    "prediction = prediction/n\n",
    "\n",
    "# MSE算出\n",
    "mse = mean_squared_error(y_test,prediction)\n",
    "\n",
    "print(\"決定木:{}\".format(mse))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "###################\n",
    "#【問題3】スタッキングのスクラッチ実装\n",
    "###################\n",
    "\n",
    "\n",
    "class Stacking():\n",
    "    \"\"\"スタッキング\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth, splits, models):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_depth : スタッキングの最大深さ\n",
    "        splits : データ分割数\n",
    "        models : 使用モデル一覧\n",
    "        fit_models : 学習済みモデル保存用リスト\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.n_splits = splits\n",
    "        self.models = models\n",
    "        self.fit_models = []\n",
    "\n",
    "    def calc_blending(self,X,y,model):\n",
    "        \"\"\"ブレンドデータ生成\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        y : 目的変数\n",
    "        m : モデル\n",
    "        \"\"\"\n",
    "        # blendingの初期化\n",
    "        blending = np.zeros(len(X))#ndarrayで演算するのでnp.zerosを使う\n",
    "\n",
    "        # KFoldの分割設定をインスタンス化\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=False)\n",
    "\n",
    "        #Kfインスタンス化した(分割設定済の）splitメソッドでXをtrainとtestに分割\n",
    "        for train_index, test_index in kf.split(X):#kf.split(X)はself.n_splitsの４回回る\n",
    "            print(\"train_index:{}\".format(train_index)) #------検証中--------\n",
    "            print(\"test_index:{}\".format(test_index)) #------検証中--------\n",
    "\n",
    "\n",
    "\n",
    "            # データ分割\n",
    "            X_train, X_test = X[train_index], X[test_index]#\n",
    "            y_train, y_test = y[train_index], y[test_index]#\n",
    "            y_train = y_train.ravel()#.ravel()で２次元を１次元に変換\n",
    "            y_test = y_test.ravel()#.ravel()で２次元を１次元に変換\n",
    "            print(\"X_train:{}\\nX_test:{}\".format(X_train, X_test)) #------検証中--------\n",
    "            print(\"\\n\")\n",
    "            print(\"y_train:{}\\ny_test:{}\".format(y_train, y_test)) #------検証中--------\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            # 学習\n",
    "            model.fit(X_train, y_train)#self.n_splitsの４回forで学習する\n",
    "\n",
    "            # self.fit_modelsに学習済みモデルの保存\n",
    "            self.fit_models.append(model)\n",
    "            print(\"self.fit_models:{}\".format(self.fit_models)) #------検証中--------\n",
    "            print(\"\\n\")\n",
    "\n",
    "            # テストデータのインデックスに予測値を格納\n",
    "            blending[test_index] = model.predict(X_test)\n",
    "\n",
    "        return blending\n",
    "\n",
    "    def fit(self,X,y,depth):\n",
    "        \"\"\"該当深さの学習実行\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        y : 目的変数\n",
    "        depth : スタッキングの「現在の」深さ\n",
    "        \"\"\"\n",
    "        # スタッキングの「現在の」深さをメンバ変数化\n",
    "        self.depth=depth\n",
    "\n",
    "        # 最大深さまで到達していれば、その深さのモデルを学習させて処理終了\n",
    "        if self.depth == self.max_depth:\n",
    "            # 当該深さでのモデルを取得\n",
    "            self.model = self.models[self.depth]\n",
    "            # 学習\n",
    "            self.model.fit(X,y)\n",
    "            return\n",
    "\n",
    "        # 当該深さでのモデルを取得\n",
    "        models = self.models[self.depth]\n",
    "        self.blending = np.zeros([len(X),len(models)])\n",
    "\n",
    "        # この階層の全てのモデルで学習\n",
    "        for i,model in enumerate(models):\n",
    "            _blending = self.calc_blending(X,y,model)\n",
    "            self.blending[:,i] = _blending\n",
    "\n",
    "        # 再帰学習\n",
    "        # コンストラクタ生成の際の引数は同じ\n",
    "        self.stk = Stacking(self.max_depth, self.n_splits, self.models)\n",
    "\n",
    "        # 学習実行の際は、ブレンドデータを説明変数として渡す。深さも1加えてやる\n",
    "        self.stk.fit(self.blending,y,depth+1)\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        y : 目的変数\n",
    "        depth : スタッキングの「現在の」深さ\n",
    "        \"\"\"\n",
    "        # 最大深さの場合は最終的な予測値を出力するのみ\n",
    "        if self.depth == self.max_depth:\n",
    "            # 予測\n",
    "            prediction = self.model.predict(X)\n",
    "            # 返す\n",
    "            return prediction\n",
    "        # 最大深さに達していない場合は、再帰的に呼び出す\n",
    "        else:\n",
    "\n",
    "            # 予測値を0で初期化\n",
    "            self.prediction = np.zeros(len(X))\n",
    "            # 次の階層に渡すブレンドデータ(仮)の作成\n",
    "            self.blending = np.zeros([len(X),len(self.models[self.depth])])\n",
    "            # この階層の学習済みモデルでループ\n",
    "            count = 0 # 現在どのモデルを回しているか把握\n",
    "            for model in self.fit_models:\n",
    "                # 予測し、0で初期化している予測値に加算\n",
    "                self.prediction += model.predict(X)\n",
    "                # 1種類のモデル学習の終了判定\n",
    "                count+=1\n",
    "                if count%self.n_splits == 0:\n",
    "                    # 予測値を加算してきたので割って平均値を算出\n",
    "                    self.prediction = self.prediction/self.n_splits\n",
    "                    # その平均値を次の階層で使用する説明変数に格納\n",
    "                    self.blending[:,int(count/self.n_splits)-1] = self.prediction\n",
    "                    # 次の種類のモデルでの予測のため、予測値は初期化しておく\n",
    "                    self.prediction = np.zeros(len(X))\n",
    "\n",
    "            # 次の階層の予測関数\n",
    "            prediction = self.stk.predict(self.blending)\n",
    "            return prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index:[ 4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[0 1 2 3]\n",
      "X_train:[[1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]]\n",
      "\n",
      "\n",
      "y_train:[149350 190000 123000 110000 148800 155000  88000 225000 141000 208900\n",
      " 119200 282922]\n",
      "y_test:[745000  85000 136905 192000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[4 5 6]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 110000 148800 155000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[149350 190000 123000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6 10 11 12 13 14 15]\n",
      "test_index:[7 8 9]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[110000 148800 155000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 13 14 15]\n",
      "test_index:[10 11 12]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      " 208900 119200 282922]\n",
      "y_test:[ 88000 225000 141000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "test_index:[13 14 15]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]]\n",
      "X_test:[[1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      "  88000 225000 141000]\n",
      "y_test:[208900 119200 282922]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[0 1 2 3]\n",
      "X_train:[[1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]]\n",
      "\n",
      "\n",
      "y_train:[149350 190000 123000 110000 148800 155000  88000 225000 141000 208900\n",
      " 119200 282922]\n",
      "y_test:[745000  85000 136905 192000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[4 5 6]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 110000 148800 155000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[149350 190000 123000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6 10 11 12 13 14 15]\n",
      "test_index:[7 8 9]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[110000 148800 155000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 13 14 15]\n",
      "test_index:[10 11 12]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      " 208900 119200 282922]\n",
      "y_test:[ 88000 225000 141000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "test_index:[13 14 15]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]]\n",
      "X_test:[[1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      "  88000 225000 141000]\n",
      "y_test:[208900 119200 282922]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[0 1 2 3]\n",
      "X_train:[[1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]]\n",
      "\n",
      "\n",
      "y_train:[149350 190000 123000 110000 148800 155000  88000 225000 141000 208900\n",
      " 119200 282922]\n",
      "y_test:[745000  85000 136905 192000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), RandomForestRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[4 5 6]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 110000 148800 155000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[149350 190000 123000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), RandomForestRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6 10 11 12 13 14 15]\n",
      "test_index:[7 8 9]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[110000 148800 155000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), RandomForestRegressor(), RandomForestRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 13 14 15]\n",
      "test_index:[10 11 12]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "X_test:[[1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      " 208900 119200 282922]\n",
      "y_test:[ 88000 225000 141000]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), RandomForestRegressor(), RandomForestRegressor(), RandomForestRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "test_index:[13 14 15]\n",
      "X_train:[[4476 4476]\n",
      " [1022 1022]\n",
      " [1680 1680]\n",
      " [2022 2022]\n",
      " [1228 1228]\n",
      " [1923 1923]\n",
      " [ 900  900]\n",
      " [1203 1203]\n",
      " [1102 1102]\n",
      " [1826 1826]\n",
      " [1092 1092]\n",
      " [1983 1983]\n",
      " [1375 1375]]\n",
      "X_test:[[1352 1352]\n",
      " [1082 1082]\n",
      " [1464 1464]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      "  88000 225000 141000]\n",
      "y_test:[208900 119200 282922]\n",
      "\n",
      "\n",
      "self.fit_models:[LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), LinearRegression(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), RandomForestRegressor(), RandomForestRegressor(), RandomForestRegressor(), RandomForestRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[0 1 2 3]\n",
      "X_train:[[124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]]\n",
      "\n",
      "\n",
      "y_train:[149350 190000 123000 110000 148800 155000  88000 225000 141000 208900\n",
      " 119200 282922]\n",
      "y_test:[745000  85000 136905 192000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[4 5 6]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 110000 148800 155000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[149350 190000 123000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6 10 11 12 13 14 15]\n",
      "test_index:[7 8 9]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[110000 148800 155000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 13 14 15]\n",
      "test_index:[10 11 12]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      " 208900 119200 282922]\n",
      "y_test:[ 88000 225000 141000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "test_index:[13 14 15]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]]\n",
      "X_test:[[133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      "  88000 225000 141000]\n",
      "y_test:[208900 119200 282922]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression()]\n",
      "\n",
      "\n",
      "train_index:[ 4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[0 1 2 3]\n",
      "X_train:[[124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]]\n",
      "\n",
      "\n",
      "y_train:[149350 190000 123000 110000 148800 155000  88000 225000 141000 208900\n",
      " 119200 282922]\n",
      "y_test:[745000  85000 136905 192000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[4 5 6]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 110000 148800 155000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[149350 190000 123000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6 10 11 12 13 14 15]\n",
      "test_index:[7 8 9]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[110000 148800 155000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 13 14 15]\n",
      "test_index:[10 11 12]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      " 208900 119200 282922]\n",
      "y_test:[ 88000 225000 141000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "test_index:[13 14 15]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]]\n",
      "X_test:[[133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      "  88000 225000 141000]\n",
      "y_test:[208900 119200 282922]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[0 1 2 3]\n",
      "X_train:[[124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]]\n",
      "\n",
      "\n",
      "y_train:[149350 190000 123000 110000 148800 155000  88000 225000 141000 208900\n",
      " 119200 282922]\n",
      "y_test:[745000  85000 136905 192000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[4 5 6]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 110000 148800 155000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[149350 190000 123000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6 10 11 12 13 14 15]\n",
      "test_index:[7 8 9]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000  88000 225000 141000\n",
      " 208900 119200 282922]\n",
      "y_test:[110000 148800 155000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 13 14 15]\n",
      "test_index:[10 11 12]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "X_test:[[109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      " 208900 119200 282922]\n",
      "y_test:[ 88000 225000 141000]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "test_index:[13 14 15]\n",
      "X_train:[[442142.82286643 225000.         209708.44      ]\n",
      " [129595.68623667 119200.         113671.        ]\n",
      " [189137.0921146  155000.         185134.4       ]\n",
      " [220084.14501772 225000.         209708.44      ]\n",
      " [124487.35902962 110000.         133828.        ]\n",
      " [248455.33386206 225000.         205986.54      ]\n",
      " [ 65981.60975619  85000.          99990.        ]\n",
      " [126438.38416802 149350.         135169.5       ]\n",
      " [108770.53541174  88000.          95267.5       ]\n",
      " [235419.27303097 190000.         183982.9       ]\n",
      " [109849.67496436 119200.         122098.5       ]\n",
      " [263049.25456456 192000.         192855.93      ]\n",
      " [158509.02516285 208900.         214652.45      ]]\n",
      "X_test:[[133450.90281716 141000.         139995.05      ]\n",
      " [ 85604.99560104  88000.         104613.5       ]\n",
      " [153298.09395865 141000.         139519.35      ]]\n",
      "\n",
      "\n",
      "y_train:[745000  85000 136905 192000 149350 190000 123000 110000 148800 155000\n",
      "  88000 225000 141000]\n",
      "y_test:[208900 119200 282922]\n",
      "\n",
      "\n",
      "self.fit_models:[ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), ARDRegression(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), SGDRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n",
      "\n",
      "\n",
      "train_index:[ 4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "test_index:[0 1 2 3]\n",
      "X_train:[[ 1.20786320e+05  6.13484607e+19  1.10000000e+05]\n",
      " [ 2.76707735e+05  9.81551969e+19  1.92000000e+05]\n",
      " [ 4.69151941e+04  3.26822192e+19  1.19200000e+05]\n",
      " [ 1.39865629e+05  3.12087294e+19  8.50000000e+04]\n",
      " [ 1.65762865e+05  4.29238930e+19  1.19200000e+05]\n",
      " [ 2.81381980e+05  9.46034680e+19  2.25000000e+05]\n",
      " [ 1.22351112e+05 -1.49040340e+19  1.10000000e+05]\n",
      " [ 3.09059228e+05 -6.72530014e+19  1.55000000e+05]\n",
      " [ 1.74828480e+04 -9.32233443e+18  1.92000000e+05]\n",
      " [ 1.09164476e+05 -7.04483541e+19  1.10000000e+05]\n",
      " [ 8.10710171e+04 -4.46628961e+19  1.23000000e+05]\n",
      " [ 1.50010242e+05 -8.27599996e+19  1.10000000e+05]]\n",
      "X_test:[[2.53829017e+05 8.72485033e+19 2.25000000e+05]\n",
      " [1.54950943e+05 1.97912111e+19 8.80000000e+04]\n",
      " [1.73798021e+05 3.59847764e+19 1.55000000e+05]\n",
      " [1.83601652e+05 3.04320700e+19 1.55000000e+05]]\n",
      "\n",
      "\n",
      "y_train:[149350 190000 123000 110000 148800 155000  88000 225000 141000 208900\n",
      " 119200 282922]\n",
      "y_test:[745000  85000 136905 192000]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "HuberRegressor convergence failed: l-BFGS-b solver terminated with b'ABNORMAL_TERMINATION_IN_LNSRCH'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-300-e57343029ad2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mstk\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mStacking\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_depth\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msplits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mstk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-299-afb2d71e31f4>\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, depth)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m         \u001B[1;31m# 学習実行の際は、ブレンドデータを説明変数として渡す。深さも1加えてやる\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 102\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblending\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdepth\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-299-afb2d71e31f4>\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, depth)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m         \u001B[1;31m# 学習実行の際は、ブレンドデータを説明変数として渡す。深さも1加えてやる\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 102\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblending\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdepth\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-299-afb2d71e31f4>\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, depth)\u001B[0m\n\u001B[0;32m     92\u001B[0m         \u001B[1;31m# この階層の全てのモデルで学習\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmodel\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 94\u001B[1;33m             \u001B[0m_blending\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalc_blending\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblending\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_blending\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-299-afb2d71e31f4>\u001B[0m in \u001B[0;36mcalc_blending\u001B[1;34m(self, X, y, model)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m             \u001B[1;31m# 学習\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m             \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;31m#self.n_splitsの４回forで学習する\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m             \u001B[1;31m# self.fit_modelsに学習済みモデルの保存\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mopt_res\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstatus\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 293\u001B[1;33m             raise ValueError(\"HuberRegressor convergence failed:\"\n\u001B[0m\u001B[0;32m    294\u001B[0m                              \u001B[1;34m\" l-BFGS-b solver terminated with %s\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m                              % opt_res.message)\n",
      "\u001B[1;31mValueError\u001B[0m: HuberRegressor convergence failed: l-BFGS-b solver terminated with b'ABNORMAL_TERMINATION_IN_LNSRCH'"
     ]
    }
   ],
   "source": [
    "#0.1.2.3という要素に検証モデルの組み合わせを用意(modelsはディクトオブジェクト）\n",
    "models = {\n",
    "    0:[LinearRegression(),DecisionTreeRegressor(),RandomForestRegressor()],\n",
    "    1:[ARDRegression(),SGDRegressor(),DecisionTreeRegressor()],\n",
    "    2:[HuberRegressor(),ARDRegression(),RandomForestRegressor()],\n",
    "    3:LinearRegression()\n",
    "}\n",
    "\n",
    "#stkという名前でクラスをインスタンス化\n",
    "stk = Stacking(max_depth=3,splits=5,models=models)\n",
    "\n",
    "stk.fit(X_train,y_train,0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = stk.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rating\n",
    "mse = mean_squared_error(y_test,prediction)\n",
    "print('MSE : {:.3f}'.format(mse))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Xとyはデータフレームなので今後の計算を踏まえてndarrayに変更\n",
    "# fit_models = []\n",
    "# Xv = X.values\n",
    "# yv = y.values\n",
    "# model\n",
    "# print(\"Xv:{}\".format(Xv)) #------検証中--------\n",
    "# print(\"yv:{}\".format(yv)) #------検証中--------\n",
    "# print(\"model:{}\".format(model)) #------検証中--------\n",
    "# print(\"\\n\")\n",
    "#\n",
    "# # blendingの初期化（Xの要素数のゼロの配列を作る）\n",
    "# blending = np.zeros(len(X))\n",
    "#\n",
    "# #KFoldクラスをKFでインスタンス化と分割設定\n",
    "# kf = KFold(n_splits=4, shuffle=True)\n",
    "#\n",
    "#\n",
    "# # Xのデータを４分割に設定されたKFインスタンスのsplitメソッドで４分割\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#\n",
    "#     print(\"train_index:{}\".format(train_index)) #------検証中--------\n",
    "#     print(\"test_index:{}\".format(test_index)) #------検証中--------\n",
    "#     print(\"\\n\")\n",
    "#\n",
    "#     # データ分割\n",
    "#     X_train, X_test = Xv[train_index,:], Xv[test_index,:]\n",
    "#     y_train, y_test = yv[train_index,:], yv[test_index,:]\n",
    "#     print(\"X_train:{}\\nX_test:{}\".format(X_train, X_test)) #------検証中--------\n",
    "#     print(\"\\n\")\n",
    "#     print(\"y_train:{}\\ny_test:{}\".format(y_train, y_test)) #------検証中--------\n",
    "#\n",
    "#\n",
    "#     # yは目的変数の為１次元に変換\n",
    "#     y_train = y_train.ravel() #.ravel()で２次元を１次元に変換\n",
    "#     y_test = y_test.ravel()\n",
    "#\n",
    "#     # 学習\n",
    "#     model.fit(X_train, y_train) #X_train, y_trainは分割設定で決めたn_splitsのデータが入っている\n",
    "#\n",
    "#     # 学習済みモデルの保存\n",
    "#     fit_models.append(model)\n",
    "#\n",
    "#     # テストデータのインデックスに予測値を格納\n",
    "#     blending[test_index] = model.predict(X_test)\n",
    "\n",
    "\n",
    "# stk.calc_blending(X_train,y_train,LinearRegression)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}